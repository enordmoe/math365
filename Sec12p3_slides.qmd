---
title: "Sections 12.3: Inferences about the Slope Parameter"
subtitle: "Mathematical Statistics"
author: "MATH 365"
format:
  revealjs:
    theme: [default, custom.scss]
    incremental: false
    transition: fade
    chalkboard: true
    smaller: true
    pdf-export: true
    toc: false
    toc-depth: 1
    reveal-options:
      slideNumber: true
    html-math-method: mathjax
    preview-links: auto
    notes: true
title-slide-attributes:
  data-background-color: "#EA6820"
from: markdown+emoji
execute:
  echo: true
  cache: false
  eval: true
editor:
  markdown:
    wrap: 72
---


## Topics for Today

- Sampling distribution of $\hat{\beta}_1$
- Confidence intervals for $\beta_1$
- Hypothesis tests for $\beta_1$ (one- and two-sided)
- Simulation: distribution of regression slopes
- Using R for inference and visualization
- Regression and ANOVA connection

---

###
::: callout-note
### Motivating Question
How can we determine whether there is (significant?) evidence of a linear relationship between $x$ and $y$ in a population?
:::

---

## Sampling Distribution of $\hat{\beta}_1$

1. $E(\hat{\beta}_1) = \beta_1$  \Rightarrow unbiased
2. $\text{Var}(\hat{\beta}_1) = \frac{\sigma^2}{S_{xx}}$, where $S_{xx} = \sum(x_i - \bar{x})^2$
3. Estimate $\sigma$ with the residual standard deviation $s$, where
$$
s^2 = \frac{1}{n - 2} \sum (y_i - \hat{y}_i)^2
$$
4. Standard error of $\hat{\beta}_1$:  \quad $s_{\hat{\beta}_1} = \frac{s}{\sqrt{S_{xx}}}$

::: {.smaller}
::: callout-important
$\hat{\beta}_1$ is normally distributed under regression model assumptions.
:::
:::

---

## Theorem: Test Statistic

Under simple linear regression assumptions:

$$
T = \frac{\hat{\beta}_1 - \beta}{s_{\hat{\beta}_1}} \sim t_{n - 2}
$$

Used for:  
- Hypothesis tests for $\beta_1$  
- Confidence intervals for $\beta_1$  

---

## Confidence Interval for $\beta_1$

::: callout-note
### 100(1 - $\alpha$)% Confidence Interval
$$
\hat{\beta}_1 \pm t_{\alpha/2, n - 2} \cdot s_{\hat{\beta}_1}
$$
:::


---  



## Hypothesis Testing for $\beta_1$

**Null Hypothesis:** $H_0: \beta_1 = \beta_{10}$

**Test Statistic:**
$$
t = \frac{\hat{\beta}_1 - \beta_{10}}{s_{\hat{\beta}_1}}
$$

::: {.smaller}

| Alternative Hypothesis         | Compute $p$-value                        |
|-------------------------------|------------------------------------------|
| $H_a: \beta_1 > \beta_{10}$   | $P(t_{n - 2} > t)$                        |
| $H_a: \beta_1 < \beta_{10}$   | $P(t_{n - 2} < t)$                        |
| $H_a: \beta_1 \ne \beta_{10}$ | $2P(t_{n - 2} > |t|)$                     |

:::




---  

## Example: Funnel Lab Data 2.0 🧪

Use regression to predict $y$ (displacement or time?) from $x$ (height).

- Fit model in R
- Compute $\hat{\beta}_1$, $s_{\hat{\beta}_1}$
- Construct CI
- Test $H_0: \beta_1 = 0$


---  

## Example: Swirling Time vs Distance

:test_tube: From the student funnel lab: use `distance` to predict
`tswirl`.

**Variables:**   
- $x$ = distance up the channel (cm)   
- $y$ = swirling time (sec)    
  

```r
funneldata <- read.csv("http://people.kzoo.edu/enordmoe/math365/data/funneldata.csv")
lm_fit <- lm(tswirl ~ distance, data = funneldata)
summary(lm_fit)
plot(tswirl ~ distance, data = funneldata)
abline(lm_fit)
```

------------------------------------------------------------------------



### Simulation of Sampling Distribution 🌀 {.smaller}

Script for simulating regression line slopes:

```r
set.seed(123)
# Set values of beta0 and beta1 to simulate funnel data
beta0 <- 15
beta1 <- 0.4
n <- 18
# generate funnel-type data distances
values <- seq(12, 36, by = 3)
x <- rep(values, each = 2)
Sxx <- sum((x - mean(x))^2)
sigma <- 1
B <- 20

slopes <- numeric(B)
plot(NULL, xlim=range(x), ylim=extendrange(y), xlab="X", ylab="Y")
abline(a = beta0, b = beta1, lwd=2, col="black") # true line

for (i in 1:B) {
  y <- beta0 + beta1 * x + rnorm(n, 0, sigma)
  fit <- lm(y ~ x)
  abline(fit, col=rgb(0.1, 0.4, 1, 0.4))
  slopes[i] <- coef(fit)[2]
}

hist(slopes,
     main = expression("Sampling Distribution of " * hat(beta)[1]),
     xlab = "Slope")
```

---

## Regression and ANOVA 🔄

::: callout-note
The model utility test $H_0: \beta_1 = 0$ is equivalent to the ANOVA $F$-test.
:::

ANOVA table for regression:

| Source     | df    | SS     | MS           | F                                |
|------------|-------|--------|--------------|----------------------------------|
| Regression | 1     | SSR    | MSR          | $\frac{MSR}{MSE}$       |
| Error      | $n-2$ | SSE    | MSE=$\frac{SSE}{n - 2}$ |                                  |
| Total      | $n-1$ | SST    |              |                                  |

Relation: $t^2 = F$ when testing $\beta_1 = 0$ for a simple linear regression.

---

## Example: Cats 🐾

Fit regression model: `lm(hwt ~ bwt, data = MASS::cats)`

- Find $\hat{\beta}_1$, CI, $p$-value
- Interpret slope and significance
- Also view ANOVA output

_Hint: What assumptions are needed?_

---

## Summary

- Inference for $\beta_1$ uses $t$-distribution with $n-2$ df
- CI: $\hat{\beta}_1 \pm t \cdot s_{\hat{\beta}_1}$
- $p$-values mean the same as before
- Simulations help visualize variability of estimates
- ANOVA and regression inference are deeply linked

---

## 🤔 Reflection

> How does $S_{xx}$ affect your ability to detect a relationship?

> When would you prefer an ANOVA summary over regression output?
