---
title: "9.2 and 9.3: <br> $t$ Procedures for Two Sample and Matched Pairs Data"
subtitle: "Mathematical Statistics"
author: "MATH 365"
format:
  revealjs:
    theme: [default, custom.scss]
    incremental: false
    transition: fade
    chalkboard: true
    smaller: true
    pdf-export: true
    toc: false
    toc-depth: 1
    reveal-options:
      slideNumber: true
    html-math-method: mathjax
    preview-links: auto
    notes: true
title-slide-attributes:
  data-background-color: "#EA6820"
from: markdown+emoji
execute:
  echo: true
  cache: false
  eval: false
editor:
  markdown:
    wrap: 72
---

## Overview and Motivation :dart:

-   Two-Sample $t$-Test with Unknown Variances
-   Two-Sample $t$ Confidence Intervals
-   Why NOT Pooled $t$ Procedures :x:
-   Two-Sample Type II Error Probabilities
-   Paired $t$-Test and Confidence Intervals
-   Comparing Two-Sample vs Matched Pairs
-   $t$ Procedures for in R


---  

::: callout-note
### Motivating Question :thought_balloon:

> How can we compare two groups when we can't assume known variances?  
:::

---

## From Known Variances to Unknown üåé

- Previous sections: we assumed population variances were known
- Reality: Variances are **unknown** üìà  
- Need to estimate using sample variances  

:::{.callout-important}
The $t$-procedures allow us to account for variability in estimating population parameters!
:::

---

## Assumptions for Two-Sample $t$ Procedures

-   Two independent random samples
-   Both populations approximately **normal**
-   Independence between samples

::: callout-note
No requirement for **equal sample sizes** :white_check_mark:   
Methods are appropriate even for **small samples**.
:::

---

## Two-Sample $t$ Statistic

When assumptions are met, the standardized variable:

$$
T = \frac{\overline{X} - \overline{Y} - (\mu_1 - \mu_2)}{\sqrt{\frac{S_1^2}{m} + \frac{S_2^2}{n}}}
$$

**approximately** follows a $t$ distribution with degrees of freedom $\nu$:

$$
\nu = \frac{\left(\frac{S_1^2}{m} + \frac{S_2^2}{n}\right)^2}{\frac{(S_1^2/m)^2}{m-1} + \frac{(S_2^2/n)^2}{n-1}}
$$

:::{.notes}
Show what this looks like if we substitute se for the standard errors.
:::

---  


## Confidence Interval for $\mu_1 - \mu_2$

$$
(\overline{X} - \overline{Y}) \pm t_{\alpha/2, \nu} \sqrt{\frac{S_1^2}{m} + \frac{S_2^2}{n}}
$$

-   Same formula structure as the test statistic
-   Use estimated $\nu$ degrees of freedom

---

## Example: Sleep Hours üåôüõèÔ∏è

Comparing mean sleep hours between **early classes** and **later classes**.

- Group 1: 8:15 AM class  
- Group 2: 10:30 AM class  

The data:

``` r
sleepdata <- read.csv(file = "http://people.kzoo.edu/enordmoe/math365/data/sleepdata2samp.csv")
```


::: callout-tip
Work out:   
- Hypotheses  
- $t$ statistic  
- $P$-value  
- Confidence interval  
:::

---  

## Example: Sleep Hours Calculations  




---

## Using `t.test()` in R :desktop_computer:

```r
# Sleep variable: `hours`
# Grouping variable: `section`
# Independent samples

t.test(hours ~ section, var.equal = FALSE, data = sleepdata)
```

::: callout-note

-   Set `var.equal = FALSE` (default)  
-   Welch's approximate degrees of freedom used    

:::

---

## Why NOT Pooled $t$? üö´

::: callout-important
- Pooled $t$ assumes $\sigma_1^2 = \sigma_2^2$
- **Risky**: very sensitive to violations
- When variances are unequal ‚ûî invalid conclusions!
:::

‚úÖ Welch‚Äôs method (separate variances) is more **robust** even if sample sizes differ.

---

## Two-Sample Type II Error Probabilities for the **sleepdata**

Suppose sample size $n$ is fixed: find $\beta$ and power!

```r
# Sample sizes
group_ns    <- tapply(sleepdata$hours, sleepdata$section, length)
n1 <- group_ns["early"]
n2 <- group_ns["late"]
n_small   <- min(group_ns)

# Variances
group_vars  <- tapply(sleepdata$hours, sleepdata$section, var)  
s1sq <- group_vars["early"]
s2sq <- group_vars["late"]

# pooled sd 
pooled_var <- ((n1 - 1) * s1sq + (n2 - 1) * s2sq) / (n1 + n2 - 2)
pooled_sd <- sqrt(pooled_var)

# Solve for power (and thus beta)
result <- power.t.test(
  n = n_small,
  delta = 0.5, # Difference we want to detect
  sd = pooled_sd,
  sig.level = 0.05,
  type = "two.sample",
  alternative = "two.sided"
)

result$power    # Power
1 - result$power  # Beta
```

---

### üéØ Solve for $n$ (given desired power)**

Suppose we want 90% power. Find sample sizes

```r
# Use same mean_diff to detect a half hour difference

power.t.test(
  power = 0.90,
  delta = 0.5,
  sd = pooled_sd,
  sig.level = 0.05,
  type = "two.sample",
  alternative = "two.sided"
)
```

‚úÖ Result gives **required per-group sample size** (round UP!).



---

### Caution About Assumptions üö®


::: callout-warning
**Caution:**  
`power.t.test()` assumes **equal variances** (pooled two-sample $t$ test).  
In real studies, if population variances are **very unequal**, the actual power may differ.

> Practical advice:  
‚úÖ Small/moderate differences in variances ‚ûî fine.  
‚ö†Ô∏è Large differences ‚ûî consider simulations for accuracy!
:::


# Paired Data vs. Two-Sample Procedures

---  

### Paired Data vs. Two-Sample Procedures

-   **Paired:** same subject measured twice
-   **Two-sample:** independent groups

::: callout-warning
Misidentifying paired vs two-sample design can lead to **wrong
analysis**!
:::

---

## Examples: Paired vs Two-Sample üß†

::: callout-note
### Decide: Paired or Two-Sample?
:::

:::{.incremental}
- Compare final exam scores between two different sections  
- Measure pre- and post-test scores for the same students  
- Compare sleep hours between first-years and seniors   
- Compare effectiveness of drug A and B on same patients
:::

:::{.fragment}
::: callout-tip
Hint: Are the observations naturally linked **one-to-one**?
:::
:::

---


## Assumptions for Paired Data

- Random sample of **pairs** $(X_i, Y_i)$
- Differences $D_i = X_i - Y_i$ are normally distributed


---

## The Paired $t$ Test


$$
T = \frac{\overline{D} - \Delta_0}{S_D/\sqrt{n}}
$$

-   $\overline{D}$ is average difference  
-   $s_D$ is sample standard deviation of differences  
-   $n-1$ degrees of freedom


:::{.fragment}
::: callout-tip  
* One sample $t$ test on differences  
* Typical test: $H_0: \mu_D = 0$ (no mean difference)  
:::
:::

---

## Confidence Interval for $\mu_D$

$$
\overline{D} \pm t_{\alpha/2, n-1} \frac{S_D}{\sqrt{n}}
$$

- Same as one-sample $t$ CI applied to differences  

---

## Example: Gosset's Data :bar_chart:

Using R‚Äôs built-in Gosset **sleep** data: increase in sleep for two different drugs

``` r
# Create Gosset sleep data in wide format
gosset_data <- data.frame(
  ID = 1:10,
  drugA = c(0.7, -1.6, -0.2, -1.2, -0.1, 3.4, 3.7, 0.8, 0.0, 2.0),
  drugB = c(1.9, 0.8, 1.1, 0.1, -0.1, 4.4, 5.5, 1.6, 4.6, 3.4)
)
# t.test procedures: Equivalent approaches
t.test(gosset_data$drugA, gosset_data$drugB, paired = TRUE)

# or 
gosset_data$diff <- gosset_data$drugA - gosset_data$drugB
t.test(gosset_data$diff)
```

::: callout-note
R  carries out a one-sample $t$ test on the differences!
:::

---  

## Summary :memo:

-   Welch's Two-Sample $t$ and Paired $t$ address unknown variances
-   Avoid the pooled $t$ test
-   Carefully identify whether data are paired or independent samples
-   Best to report both $P$-values and CIs
-   Use correct `t.test()`


