# Engaging Real-World Studies for a Mathematical Statistics Course

To inspire statistical thinking in an undergraduate course, here are several recent studies (from the past ~5–7 years, published in **Journal of the American Statistical Association (JASA)** or **Annals of Applied Statistics (AoAS)**) set in real-world contexts. Each example illustrates key statistical concepts – such as observational vs. experimental design, estimation, prediction, simulation, and uncertainty – and could spark class discussions early in the course.

## Social Networks and Behavior: Testing Balance Theory (2020)  
*Source: JASA (Applications & Case Studies), 2020* – **Feng et al.** tested the old adage “the enemy of my enemy is my friend” using *social network data* from 32 rural villages ([Testing for Balance in Social Networks | Human Nature Lab | Human Nature Lab at Yale](https://humannaturelab.net/paper/testing-for-balance-in-social-networks#:~:text=Friendship%20and%20antipathy%20exist%20in,assumes%20that%20negative%20and%20positive)) ([Testing for Balance in Social Networks | Human Nature Lab | Human Nature Lab at Yale](https://humannaturelab.net/paper/testing-for-balance-in-social-networks#:~:text=independent%20interest,tie%20formation%20in%20this%20setting)). In network terms, **“balance theory”** predicts that triangles of friendships/enmities with an odd number of negative ties (an unbalanced triad) should be rare. The researchers developed a novel hypothesis test for network balance, improving on a simple permutation test that treats positive and negative ties as interchangeable ([Testing for Balance in Social Networks | Human Nature Lab | Human Nature Lab at Yale](https://humannaturelab.net/paper/testing-for-balance-in-social-networks#:~:text=negative%20ties%20that%20has%20received,Along%20the%20way%2C%20we%20prove)). They collected friendship and antagonism data and found *only marginal evidence* for this theory in the villages ([Testing for Balance in Social Networks | Human Nature Lab | Human Nature Lab at Yale](https://humannaturelab.net/paper/testing-for-balance-in-social-networks#:~:text=independent%20interest,tie%20formation%20in%20this%20setting)). **Class use:** This study can introduce how observational social data (no experiments here!) can be used to test a hypothesis. It highlights concepts of **network sampling**, **hypothesis testing** (permutation vs. analytic tests), and the challenges of modeling human relationships. Students can discuss why a naive randomization test might fail and how statistical theory (asymptotic distributions) was used to create a better test. The context – friends and enemies in a community – is engaging and relatable, showing how statistics can confirm or refute social theories.

## Public Health (Pandemic): Combining Surveys and Case Counts for COVID-19 (2024)  
*Source: JASA (Applications & Case Studies), 2024* – **Guerrier et al.** analyzed **COVID-19 prevalence in Austria** by cleverly combining two data sources: random infection **surveys** and official **case counts** ([Assessing COVID-19 in Austria with infection surveys - Faculté d'économie et de management - UNIGE](https://www.unige.ch/gsem/en/about/news-events/news/2024/estimation-covid-19-prevalence-in-austria/#:~:text=Franzens,proposed%20estimators%20and%20confidence%20intervals)). Case counts come from testing and are prone to *selection bias* (who gets tested), whereas prevalence surveys sample the population for infection. This study demonstrated that integrating biased case data as *auxiliary information* with survey results yields **more efficient estimates** of true infection prevalence ([Assessing COVID-19 in Austria with infection surveys - Faculté d'économie et de management - UNIGE](https://www.unige.ch/gsem/en/about/news-events/news/2024/estimation-covid-19-prevalence-in-austria/#:~:text=2020,proposed%20estimators%20and%20confidence%20intervals)) – in fact, much smaller surveys can achieve the same accuracy when the extra data are used. The authors accounted for **measurement error** (imperfect test sensitivity/specificity) and the survey’s complex design, and provided new estimators with confidence intervals ([Assessing COVID-19 in Austria with infection surveys - Faculté d'économie et de management - UNIGE](https://www.unige.ch/gsem/en/about/news-events/news/2024/estimation-covid-19-prevalence-in-austria/#:~:text=benefits%20of%20properly%20combining%20the,CRAN)). They even developed an R package for their methods. **Class use:** This example can kick off discussions on **observational vs. experimental design** – highlighting why a random sample (survey) is the gold standard for prevalence estimation while raw case counts are observational and biased. It illustrates **parameter estimation** (estimating infection rate) and shows how combining data can improve **efficiency** (smaller sample for same precision) ([Assessing COVID-19 in Austria with infection surveys - Faculté d'économie et de management - UNIGE](https://www.unige.ch/gsem/en/about/news-events/news/2024/estimation-covid-19-prevalence-in-austria/#:~:text=2020,proposed%20estimators%20and%20confidence%20intervals)). It also raises the idea of **bias correction** and **uncertainty quantification** (through confidence intervals) in a timely, real-world context that students can appreciate given their experience with pandemic data.

## Environmental Statistics: Volcanic Eruption Impacts on Climate (2024)  
*Source: AoAS, to appear 2024* – **Shi-Jun, Shand & Li** developed a method to quantify how a major environmental event – the 1991 **Mt. Pinatubo volcanic eruption** – affected global climate ([[2409.08908] Tracing the impacts of Mount Pinatubo eruption on global climate using spatially-varying changepoint detection](https://arxiv.org/abs/2409.08908#:~:text=,We)). Large eruptions inject aerosols that cool the planet, but these effects vary over time and region. The study proposed a **Bayesian spatially-varying changepoint model** to detect when and where climate indicators changed due to the eruption ([[2409.08908] Tracing the impacts of Mount Pinatubo eruption on global climate using spatially-varying changepoint detection](https://arxiv.org/abs/2409.08908#:~:text=,We)). After validating the method on simulations, they applied it to global data (1985–1995 monthly aerosol optical depth and surface temperatures) to pinpoint climate **changepoints** following Pinatubo ([[2409.08908] Tracing the impacts of Mount Pinatubo eruption on global climate using spatially-varying changepoint detection](https://arxiv.org/abs/2409.08908#:~:text=detect%20and%20estimate%20spatially,Pinatubo%20eruption)). This helped *“trace” the timing and magnitude of the eruption’s impact across different regions*. **Class use:** This example showcases **statistical modeling** in an environmental context and the idea of **change detection**: how can we statistically discern a signal (the eruption’s effect) amid natural variability? It underscores the use of **observational data** (we can’t experimentally erupt volcanoes!) and introduces **Bayesian thinking** and **spatial analysis** in an accessible way – for instance, discussing how one might tell if a sequence of temperatures significantly dropped around 1991. The narrative of a volcano changing the climate grabs attention, and students can appreciate how stats is used for **prediction** (forecasting impacts of future events by understanding this one) and **uncertainty quantification** (how confident are we in detecting a real change vs. random fluctuation).

## Racial Equity and Policy: Fairness in Recidivism Risk Prediction (2019)  
*Source: AoAS, 2019* – **Johndrow & Lum** addressed a pressing policy issue: racial bias in algorithmic **risk assessments**. Courts and parole boards increasingly use predictive models to forecast recidivism (likelihood of re-offense) for decisions like bail or parole. But these models learn from historical data, which can encode societal biases. This study introduced **an algorithm to “remove” sensitive information (race)** from the predictor variables, aiming to make risk predictions race-neutral ([Removing human bias from predictive modeling](https://phys.org/news/2019-10-human-bias.html#:~:text=Predictive%20modeling%20is%20supposed%20to,method%20to%20remove%20those%20biases)). By adjusting the data before model training, the method strips out the part of variation correlated with race, thus preventing the algorithm from indirectly using race (via correlated factors) ([Removing human bias from predictive modeling](https://phys.org/news/2019-10-human-bias.html#:~:text=biases%20that%20are%20built%20into,method%20to%20remove%20those%20biases)) ([Removing human bias from predictive modeling](https://phys.org/news/2019-10-human-bias.html#:~:text=,discriminated%20against%20by%20these%20algorithms)). In their case study on recidivism, the adjusted model achieved nearly identical accuracy while **eliminating racial disparity** in predictions ([Removing human bias from predictive modeling](https://phys.org/news/2019-10-human-bias.html#:~:text=,discriminated%20against%20by%20these%20algorithms)). **Class use:** This example is excellent for discussing the difference between **causation and correlation** and the pitfalls of **observational data**. Students can debate why a model might unintentionally discriminate and how one could test or fix that. It directly ties to **ethical use of statistics** and introduces the concept of **algorithmic fairness**. In statistical terms, it involves **prediction** modeling and a form of **simulation/adjustment**: effectively simulating a world where race does not influence other variables. The context (criminal justice and bias) resonates in a liberal arts setting. In class, one might use this to illustrate why just naively fitting a model can perpetuate bias, underscoring the importance of careful study design and consideration of confounders.

## Sports Analytics: Separating Skill and Luck in Sports Outcomes (2018)  
*Source: AoAS, 2018* – **Lopez, Matthews & Baumer** took on a fun question relevant to any sports fan: *“How often does the best team win?”* ([
"How Often Does the Best Team Win? A Unified Approach to Understanding " by Michael J. Lopez, Gregory J. Matthews et al.
](https://ecommons.luc.edu/math_facpubs/25/#:~:text=Statistical%20applications%20in%20sports%20have,of%20team%20strengths%2C%20as%20well)). They examined the four major North American pro leagues (NBA, NFL, MLB, NHL) to quantify how much **random chance** versus team **skill** determines game outcomes. Using a **Bayesian state-space model** fitted to betting odds and game results, they estimated each team’s underlying strength and the variability in performance from game to game and season to season ([
"How Often Does the Best Team Win? A Unified Approach to Understanding " by Michael J. Lopez, Gregory J. Matthews et al.
](https://ecommons.luc.edu/math_facpubs/25/#:~:text=concentrated%20on%20a%20single%20sport%2C,NHL)). The results provided a cross-sport comparison of **uncertainty in outcomes**: the NBA, for example, showed the least randomness (talent differences and home advantage play a big role), whereas sports like hockey and baseball showed a lot more game-to-game randomness ([
"How Often Does the Best Team Win? A Unified Approach to Understanding " by Michael J. Lopez, Gregory J. Matthews et al.
](https://ecommons.luc.edu/math_facpubs/25/#:~:text=each%20of%20the%20National%20Football,models%20might%20be%20usefully%20applied)). They even proposed new metrics for league competitiveness (e.g., how often the top team wins the championship under various playoff formats) ([
"How Often Does the Best Team Win? A Unified Approach to Understanding " by Michael J. Lopez, Gregory J. Matthews et al.
](https://ecommons.luc.edu/math_facpubs/25/#:~:text=that%20the%20NBA%20demonstrates%20both,models%20might%20be%20usefully%20applied)). **Class use:** This study is a great way to hook students with a familiar topic while illustrating **statistical modeling and inference**. Key concepts include **signal vs. noise** – here, separating true team ability (signal) from random upsets or slumps (noise) ([
"How Often Does the Best Team Win? A Unified Approach to Understanding " by Michael J. Lopez, Gregory J. Matthews et al.
](https://ecommons.luc.edu/math_facpubs/25/#:~:text=Statistical%20applications%20in%20sports%20have,of%20team%20strengths%2C%20as%20well)). One can discuss **parameter estimation** (estimating “team strength” as a parameter) and **variability** (why a seven-game World Series might crown the best team more reliably than a single Super Bowl). It’s also a gentle intro to **Bayesian ideas** (updating beliefs about team skill with data) without heavy technical detail. Students can relate to the idea that in some fields outcomes are more predictable than others, and it opens a conversation about **probability, uncertainty, and prediction** in everyday life (e.g., sports betting odds as implicit predictions).

---

Each of these examples connects core statistical principles to engaging, real-world questions – from friendships and feuds to pandemics, climate shocks, justice, and sports. By discussing studies like these (with appropriate simplification), students can see **why** statistical methods matter and how statistical thinking applies across diverse domains. The year and source are noted so you can retrieve the articles for more detail or assign portions for reading. Each study’s narrative can frame a class discussion or a case study, illustrating abstract concepts with concrete scenarios and thus motivating students for the theory to come. 

**Sources:** The descriptions above are based on the cited articles and summaries from JASA and AoAS (2018–2024) ([Testing for Balance in Social Networks | Human Nature Lab | Human Nature Lab at Yale](https://humannaturelab.net/paper/testing-for-balance-in-social-networks#:~:text=Friendship%20and%20antipathy%20exist%20in,assumes%20that%20negative%20and%20positive)) ([Assessing COVID-19 in Austria with infection surveys - Faculté d'économie et de management - UNIGE](https://www.unige.ch/gsem/en/about/news-events/news/2024/estimation-covid-19-prevalence-in-austria/#:~:text=2020,proposed%20estimators%20and%20confidence%20intervals)) ([[2409.08908] Tracing the impacts of Mount Pinatubo eruption on global climate using spatially-varying changepoint detection](https://arxiv.org/abs/2409.08908#:~:text=,We)) ([Removing human bias from predictive modeling](https://phys.org/news/2019-10-human-bias.html#:~:text=Predictive%20modeling%20is%20supposed%20to,method%20to%20remove%20those%20biases)) ([
"How Often Does the Best Team Win? A Unified Approach to Understanding " by Michael J. Lopez, Gregory J. Matthews et al.
](https://ecommons.luc.edu/math_facpubs/25/#:~:text=each%20of%20the%20National%20Football,models%20might%20be%20usefully%20applied)), which provide further details and context.
