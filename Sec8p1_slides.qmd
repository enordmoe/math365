---
title: "8.1 Hypotheses and Test Procedures"
subtitle: "Mathematical Statistics"
author: "MATH 365"
format:
  revealjs:
    theme: [default, custom.scss]
    incremental: false
    transition: fade
    chalkboard: true
    center: true
    smaller: true
    pdf-export: true
    toc: false
    toc-depth: 1
    reveal-options:
      slideNumber: true
    html-math-method: mathjax
    preview-links: auto
    notes: true
title-slide-attributes:
  data-background-color: "#EA6820"
from: markdown+emoji
execute:
  echo: true
  cache: false
  eval: false
editor:
  markdown:
    wrap: 72
---

## Section Overview

-   Hypotheses :brain:
-   P-values
-   Test procedures :balance_scale:
-   Type I and II errors :exclamation::question:
-   Real-world example: Penny Spins ðŸª™

------------------------------------------------------------------------

## Basic Terminology :mag:

> A **statistical hypothesis** is a claim about a population parameter.

-   **Null hypothesis** $H_0$: initial assumption ("status quo")\

-   **Alternative hypothesis** $H_a$: competing claim ("something has
    changed!", "research hypothesis")


-   **Test statistic:**  a function of the sample data that summarizes the evidence relevant to a specific statistical hypothesis.  


---  




## Example: Spinning a Penny ðŸª™

> Suppose we spin a penny 20 times. Let $X$ = number of heads.

-   $H_0: p = 0.5$
-   $H_a: p < 0.5$

:abacus: If we observe 6 heads, how unusual is that?\

-   Compute $p$-value using binomial probabilities.

::: {.notes}

(Work through the calculations together on board!)

:::  

---

## Introducing the P-value

> **Definition:** The P-value is the probability, calculated assuming that $H_0$ is true, of obtaining a value of the test statistic **at least as contradictory** to $H_0$ as what we observed.

### Key features:

1. The P-value is a **probability**.
2. It is computed **assuming $H_0$ is true**.
3. It measures **evidence against $H_0$**.

:::{.fragment}

In plain terms, the P-value tells us how surprising our data would be **if $H_0$ were true**.

:::


---  

## Visual Overview :framed_picture:

```{r}
#| code-fold: true
#| eval: true
# Parameters
n <- 20
p <- 0.5

# Create the data
x_vals <- 0:n
probs <- dbinom(x_vals, size = n, prob = p)

# Set up colors: red for rejection region (X <= 6), blue otherwise
colors <- ifelse(x_vals <= 6, "red", "lightblue")

# Set up basic plot
barplot(height = probs,
        names.arg = x_vals,
        col = colors,
        space = 0,
        border = "black",
        xlab = "Number of Heads",
        ylab = "Probability",
        main = "Binomial Distribution, n=20, p=0.5")

# Add "Rejection Region" label
text(x = 4, y = max(probs)*0.2, labels = "Rejection\nRegion", pos = 3, col = "red")
```


---  

## Interpreting the P-value

> A small P-value means the observed outcome is **unlikely** under $H_0$ and suggests support for $H_a$.

> A large P-value means the outcome is **plausible** under $H_0$ â€” we do not reject.

ðŸ§ª It is customary to call data **significant** when $H_0$ is rejected, and **not significant** otherwise.

------------------------------------------------------------------------



### Formalized Hypothesis Testing Procedure :hammer_and_wrench:

A hypothesis test procedure is specified by the following:

1. A **test statistic**, a function of the sample data on which the decision (reject $H_0$ or do not
reject $H_0$) is to be based;  
2. A **rejection region**, $\cal R$, the set of all test statistic values for which $H_0$ will be rejected.


::: {.callout-important .callout}
## Important

The null hypothesis will then be rejected if and only if the observed or computed test statistic value
falls in the rejection region.

:::


------------------------------------------------------------------------




## Errors in Hypothesis Testing :warning: {.smaller}

> Two kinds of mistakes can happen:

-   **Type I error**: Reject $H_0$ when it is true (false alarm)
    -   Probability = $\alpha$
-   **Type II error**: Fail to reject $H_0$ when $H_a$ is true (missed
    discovery)
    -   Probability = $\beta$ 
-   **Power**: correctly reject $H_0$ when $H_a$ is true 
    -   Probability = $1-\beta$   

:star2: Trade-off: smaller $\alpha$ often means larger $\beta$.


--- 

## Type I and Type II Errors Summary

<div style="display: flex; justify-content: center;">
  <table style="border-collapse: collapse; font-size: 1.1em;">
    <thead>
      <tr style="background-color: #e2e8f0;">
        <th style="border: 1px solid #ccc; padding: 20px;"></th>
        <th style="border: 1px solid #ccc; padding: 20px;">Null is <b>True</b></th>
        <th style="border: 1px solid #ccc; padding: 20px;">Null is <b>False</b></th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <th style="border: 1px solid #ccc; padding: 10px;">Rejected</th>
        <td style="background-color: #f87171; border: 1px solid #ccc; padding: 20px;">
          <b>Type I error</b><br>
          False positive<br>
          Probability = <span style="font-family: 'STIXGeneral', 'Cambria Math', serif;">&alpha;</span>
        </td>
        <td style="background-color: #5eead4; border: 1px solid #ccc; padding: 20px;">
          <b>Correct decision</b><br>
          True positive (Power)<br>
          Probability = 1 âˆ’ <span style="font-family: 'STIXGeneral', 'Cambria Math', serif;">&beta;<br></span>
        </td>
      </tr>
      <tr>
        <th style="border: 1px solid #ccc; padding: 20px;">Not rejected</th>
        <td style="background-color: #5eead4; border: 1px solid #ccc; padding: 20px;">
          <b>Correct decision</b><br>
          True negative<br>
          Probability = 1 âˆ’ <span style="font-family: 'STIXGeneral', 'Cambria Math', serif;">&alpha;</span>
        </td>
        <td style="background-color: #f87171; border: 1px solid #ccc; padding: 20px;">
          <b>Type II error</b><br>
          False negative<br>
          Probability = <span style="font-family: 'STIXGeneral', 'Cambria Math', serif;">&beta;</span>
        </td>
      </tr>
    </tbody>
  </table>
</div>


------------------------------------------------------------------------

## Thought Question :thought_balloon:

> In the penny spinning example, what would a Type I error mean?   
> What would a Type II error mean?    

:speaking_head: Discuss and share your interpretations!


------------------------------------------------------------------------

## Continuing Example: Penny Spin Test ðŸª™

* Suppose we set: - $\alpha = 0.05$ $\Rightarrow$ Rejection region: $X \leq 6$  

* If $X \leq 6$, we **reject** $H_0$. Otherwise, we **fail to reject**
$H_0$.  

Question 1: What is the actual Type I error probability?
<br>
<br>

:::{.fragment}

Question 2: What is the Type II error probability if actually $p=0.4$? If $p=0.3$ or $p=.2$  

:::

--- 

### Type II Error Curve for Penny Spinning Test with $\alpha = .05$ 

```{r}
#| eval: true
curve(1-pbinom(6, 20, x), from = 0, to = .5, xlab = "Values of p'", 
      ylab = "Type II Error Probability")
```

* Note: This assumes we reject $H_0$ for $X\le 6$.  

---

### Power Curve for Penny Spinning Test with $\alpha = .05$ 

```{r}
#| eval: true
curve(pbinom(6, 20, x), from = 0, to = .5, xlab = "Values of p'", 
      ylab = "Power (probability)")
```

* Note: Power is greater when alternative $p'$ is further away from null $p=0.5$.  

---

## Tradeoff Between $\alpha$ and $\beta$ {.smaller}

> **Proposition:**    
> Suppose an experiment and sample size are fixed, and a test statistic is chosen.    
> Then decreasing the size of the rejection region to obtain a smaller value of $\alpha$ results in a larger value of $\beta$ for any particular parameter value consistent with $H_a$.  

:::{.fragment}

#### ðŸ§  Key Ideas:  

:::{.incremental}
- Reducing $\alpha$ â†’ Shrinks rejection region â†’ Harder to reject $H_0$.  
- This caution **increases** the chance of a **Type II error** (failing to detect a true effect).  
- There is **no free lunch**: controlling one error rate worsens the other.  
:::
:::

:::{.fragment} 

#### ðŸ“ˆ Practical Meaning:  

- A test with $\alpha = \frac{1}{20}$ is more conservative than one with $\alpha = \frac{1}{10}$.  
- Smaller $\alpha$ protects against false positives, but at the **cost of lower power**.  
- Choosing $\alpha$ involves considering the **relative seriousness** of Type I vs Type II errors.  

:::

------------------------------------------------------------------------



## Decision Rule Based on P-value :triangular_ruler:

> Select a significance level $\alpha$ (the desired Type I error rate). Then:

- Reject $H_0$ if P-value $\leq \alpha$  
- Do not reject $H_0$ if P-value $> \alpha$

:::{.callout-note}
These rules are equivalent to using a rejection region.
:::



------------------------------------------------------------------------

## Proposition: P-value as a threshold

> The **P-value is the smallest significance level** $\alpha$ at which $H_0$ can be rejected.

:::{.callout-tip}
Because of this, the P-value is also called the **observed significance level** (OSL) for the data.
:::


------------------------------------------------------------------------

## Quick Check :white_check_mark:

**Decide if each statement is True or False:**

-   You can "accept" $H_0$.\
-   A smaller $\alpha$ means a lower chance of a Type I error.\
-   Type II error means falsely claiming an effect exists.

::: notes
(Show answers after discussion.)
:::

------------------------------------------------------------------------  


## Interval vs Hypothesis Testing :chart_with_upwards_trend::chart_with_downwards_trend: {.smaller}

| Interval Estimation                 | Hypothesis Testing                |
|:------------------------------------|:----------------------------------|
| Estimate a parameter                | Make a decision about a parameter |
| Provide a range of plausible values | Decide whether to reject $H_0$    |
| Focus on uncertainty                | Focus on evidence                 |

**Question:** How might the ideas of sampling variability be relevant to
a hypothesis test?

------------------------------------------------------------------------

## Summary :scroll:

-   Hypothesis tests evaluate claims about parameters.
-   Two competing hypotheses: $H_0$ and $H_a$.\
-   Key errors:
    -   Type I ($\alpha$): false rejection\
    -   Type II ($\beta$): false acceptance\
-   Balance between $\alpha$ and $\beta$ is important!
-   P-value provides an alternative but equivalent test decision rule.
-   Smaller P-values = stronger evidence against $H_0$.


